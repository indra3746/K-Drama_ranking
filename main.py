import requests
from bs4 import BeautifulSoup
import datetime
import os
import re
import traceback

# 1. í…”ë ˆê·¸ë¨ ì „ì†¡
def send_telegram(text):
    token = os.environ.get("TELEGRAM_TOKEN")
    chat_id = os.environ.get("CHAT_ID")
    if token and chat_id and len(text) > 0:
        try:
            url = f"https://api.telegram.org/bot{token}/sendMessage"
            requests.post(url, json={"chat_id": chat_id, "text": text, "disable_web_page_preview": True})
        except Exception as e:
            print(f"ì „ì†¡ ì‹¤íŒ¨: {e}")

# ==========================================
# [ë¹„ìƒìš© ìˆ˜ë™ ë¦¬ìŠ¤íŠ¸]
# ë„¤ì´ë²„ ì ‘ì†ì´ ì°¨ë‹¨ë  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´, í˜„ì¬ ë°©ì˜ì¤‘ì¸ ì£¼ìš” ë“œë¼ë§ˆë¥¼ ë„£ì–´ë‘  (ì§€ì† ì—…ë°ì´íŠ¸ ê¶Œì¥)
MANUAL_DRAMA_LIST = [
    "ëŸ¬ë¸Œ ë¯¸", "ìŠ¤í”„ë§ í”¼ë²„", "ì•„ì´ëŒì•„ì´", "íŒì‚¬ ì´í•œì˜", "í™”ë ¤í•œ ë‚ ë“¤", 
    "ì€ì• í•˜ëŠ” ë„ì ë‹˜ì•„", "ì²« ë²ˆì§¸ ë‚¨ì", "ì¹œë°€í•œ ë¦¬í”Œë¦¬", "ê²°í˜¼í•˜ì ë§¹ê½ì•„",
    "ìš©ê°ë¬´ìŒ ìš©ìˆ˜ì •", "ì„¸ ë²ˆì§¸ ê²°í˜¼", "ìš°ì•„í•œ ì œêµ­", "ë‚˜ì˜ í•´ë¦¬ì—ê²Œ",
    "ì¡°ë¦½ì‹ ê°€ì¡±", "ì´í˜¼ìˆ™ë ¤ìº í”„", "ì‹¬ì¥ì„ í›”ì¹œ ê²Œì„", "ìŠ¤ìº”ë“¤", "ì¹œì ˆí•œ ì„ ì£¼ì”¨",
    "ëª¨í…” ìº˜ë¦¬í¬ë‹ˆì•„", "ë³´ë¬¼ì„¬", "í˜‘ìƒì˜ ê¸°ìˆ ", "ì‚´ë¡± ë“œ í™ˆì¦ˆ", "ê·¸ë˜, ì´í˜¼í•˜ì"
]
# ==========================================

# 2. ë„¤ì´ë²„ 'ë°©ì˜ì¤‘ ë“œë¼ë§ˆ' ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ (Whitelist ìƒì„±)
def get_active_dramas():
    print("ğŸ“‹ ë„¤ì´ë²„ 'ë°©ì˜ì¤‘ ë“œë¼ë§ˆ' ëª©ë¡ í™•ë³´ ì‹œë„...")
    active_titles = set()
    
    # 1ë‹¨ê³„: ìˆ˜ë™ ë¦¬ìŠ¤íŠ¸ ë¨¼ì € ë“±ë¡ (ê¸°ë³¸ê°’)
    for t in MANUAL_DRAMA_LIST:
        active_titles.add(t.replace(" ", ""))
        
    # 2ë‹¨ê³„: ë„¤ì´ë²„ ê²€ìƒ‰ ì‹œë„
    url = "https://search.naver.com/search.naver?where=nexearch&sm=tab_etc&query=ë°©ì˜ì¤‘ë“œë¼ë§ˆ"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ë„¤ì´ë²„ ë“œë¼ë§ˆ ì¹´ë“œ ë¦¬ìŠ¤íŠ¸ (ìŠ¤í¬ë¦°ìƒ· ê¸°ë°˜ êµ¬ì¡° ì¶”ì •)
        # ë³´í†µ class="text" í˜¹ì€ "title" ì•ˆì— ì œëª©ì´ ìˆìŒ
        titles = soup.select(".info_area .tit, .text, .title")
        
        crawled_count = 0
        for t in titles:
            title = t.get_text(strip=True)
            # ê¸€ììˆ˜ê°€ ë„ˆë¬´ ì§§ê±°ë‚˜(1ì), 'ì‹œì²­ë¥ ' ê°™ì€ ì¡ë‹¤í•œ í…ìŠ¤íŠ¸ ì œì™¸
            if len(title) > 1 and "ì‹œì²­ë¥ " not in title:
                clean_t = title.replace(" ", "")
                active_titles.add(clean_t)
                crawled_count += 1
        
        if crawled_count > 0:
            print(f"   âœ… ë„¤ì´ë²„ í¬ë¡¤ë§ ì„±ê³µ: {crawled_count}ê°œ ì¶”ê°€ë¨")
        else:
            print("   âš ï¸ ë„¤ì´ë²„ í¬ë¡¤ë§ ì‹¤íŒ¨ (êµ¬ì¡° ë³€ê²½ ë˜ëŠ” ì°¨ë‹¨), ìˆ˜ë™ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©")
            
    except Exception as e:
        print(f"   âš ï¸ ë„¤ì´ë²„ ì ‘ì† ì—ëŸ¬: {e}")
        
    print(f"   â„¹ï¸ ìµœì¢… ê°ì‹œ ëŒ€ìƒ ë“œë¼ë§ˆ: {len(active_titles)}ê°œ")
    return active_titles

# 3. ë‹ìŠ¨ì½”ë¦¬ì•„ ë°ì´í„° ìˆ˜ì§‘
def fetch_nielsen_data(url, type_name):
    print(f"[{type_name}] ë‹ìŠ¨ ë°ì´í„° ìˆ˜ì§‘: {url}")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.nielsenkorea.co.kr/'
    }
    
    try:
        res = requests.get(url, headers=headers, timeout=15)
        res.encoding = 'euc-kr' # í•œê¸€ ê¹¨ì§ ë°©ì§€ í•„ìˆ˜
        
        soup = BeautifulSoup(res.text, 'html.parser')
        results = []
        
        table = soup.find("table", class_="ranking_tb")
        if not table:
            print(f"   âš ï¸ í…Œì´ë¸” ì—†ìŒ (ì°¨ë‹¨ ë˜ëŠ” í˜ì´ì§€ ì˜¤ë¥˜)")
            return []
            
        rows = table.find_all("tr")
        for row in rows:
            cols = row.find_all("td")
            if len(cols) < 4: continue
            
            try:
                channel = cols[1].get_text(strip=True)
                raw_title = cols[2].get_text(strip=True)
                rating = cols[3].get_text(strip=True)
                
                # ì‹œì²­ë¥  ìˆ«ì ë³€í™˜ (ì •ë ¬ìš©)
                try:
                    rating_val = float(rating.replace("%", "").strip())
                except:
                    rating_val = 0.0
                
                results.append({
                    "channel": channel,
                    "title": raw_title, # ì›ë³¸ ì œëª© (ë‚˜ì¤‘ì— ê°€ê³µ)
                    "rating": rating,
                    "rating_val": rating_val
                })
            except: continue
            
        return results
    except Exception as e:
        print(f"   âŒ ì ‘ì† ì—ëŸ¬: {e}")
        return []

# 4. ë°ì´í„° ë§¤ì¹­ (í•µì‹¬ ë¡œì§)
def filter_dramas(nielsen_data, active_set):
    filtered = []
    
    for item in nielsen_data:
        raw_title = item['title']
        clean_raw = raw_title.replace(" ", "")
        
        # 1ë‹¨ê³„: ê´„í˜¸ ì•ˆì˜ ì œëª© ì¶”ì¶œ "ì¼ì¼ë“œë¼ë§ˆ(ê²°í˜¼í•˜ìë§¹ê½ì•„)" -> "ê²°í˜¼í•˜ìë§¹ê½ì•„"
        match = re.search(r'\((.*?)\)', raw_title)
        extracted_title = ""
        if match:
            extracted_title = match.group(1).strip()
        
        # 2ë‹¨ê³„: ë§¤ì¹­ ê²€ì‚¬
        is_found = False
        display_title = raw_title
        
        # (1) ê´„í˜¸ ì•ˆ ì œëª©ì´ Whitelistì— ìˆëŠ”ê°€?
        if extracted_title:
            if extracted_title.replace(" ", "") in active_set:
                is_found = True
                display_title = extracted_title
        
        # (2) ì›ë³¸ ì œëª© ìì²´ê°€ Whitelistì— í¬í•¨ë˜ëŠ”ê°€? (ê´„í˜¸ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„)
        if not is_found:
            for target in active_set:
                if target in clean_raw: # ì˜ˆ: "ìŠ¤í”„ë§í”¼ë²„" in "ì›”í™”ë“œë¼ë§ˆìŠ¤í”„ë§í”¼ë²„"
                    is_found = True
                    # display_titleì€ ë‹ìŠ¨ ì›ë³¸ ìœ ì§€í•˜ê±°ë‚˜, í•„ìš”ì‹œ ë§¤ì¹­ëœ ê±¸ë¡œ êµì²´
                    break
                    
        if is_found:
            item['display_title'] = display_title
            filtered.append(item)
            
    # ì‹œì²­ë¥  ìˆœ ì •ë ¬
    filtered.sort(key=lambda x: x['rating_val'], reverse=True)
    return filtered

# 5. ë©”ì¸ ì‹¤í–‰
def main():
    try:
        # ë‚ ì§œ ê³„ì‚° (KST)
        kst_now = datetime.datetime.utcnow() + datetime.timedelta(hours=9)
        yesterday = kst_now - datetime.timedelta(days=1)
        days = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
        date_str = yesterday.strftime(f"%Y-%m-%d({days[yesterday.weekday()]})")
        
        print(f"--- ì‹¤í–‰ ì‹œì‘ ({date_str} ê¸°ì¤€) ---")
        
        # 1. ê°ì‹œ ëŒ€ìƒ ë“œë¼ë§ˆ ë¦¬ìŠ¤íŠ¸ í™•ë³´ (Naver + Manual)
        active_set = get_active_dramas()
        
        # 2. ë‹ìŠ¨ ë°ì´í„° ìˆ˜ì§‘ (Raw Data)
        url_t = "https://www.nielsenkorea.co.kr/tv_terrestrial_day.asp?menu=Tit_1&sub_menu=1_1&area=00"
        raw_t = fetch_nielsen_data(url_t, "ì§€ìƒíŒŒ")
        
        url_c = "https://www.nielsenkorea.co.kr/tv_cable_day.asp?menu=Tit_2&sub_menu=2_1&area=00"
        raw_c = fetch_nielsen_data(url_c, "ì¢…í¸/ì¼€ì´ë¸”")
        
        # 3. ë§¤ì¹­ í•„í„°ë§
        final_t = filter_dramas(raw_t, active_set)
        final_c_all = filter_dramas(raw_c, active_set)
        
        # 4. ì¢…í¸/ì¼€ì´ë¸” ë¶„ë¦¬
        jongpyeon_chs = ["JTBC", "MBN", "TV CHOSUN", "TVì¡°ì„ ", "ì±„ë„A"]
        final_j = []
        final_c = []
        
        for item in final_c_all:
            ch_upper = item['channel'].upper().replace(" ", "")
            if any(j in ch_upper for j in jongpyeon_chs):
                final_j.append(item)
            else:
                final_c.append(item)
        
        # ë¶„ë¦¬ í›„ ì¬ì •ë ¬
        final_j.sort(key=lambda x: x['rating_val'], reverse=True)
        final_c.sort(key=lambda x: x['rating_val'], reverse=True)
        
        # 5. ë¦¬í¬íŠ¸ ì‘ì„±
        report = f"ğŸ“º {date_str} ë“œë¼ë§ˆ ì‹œì²­ë¥  ë­í‚¹\n(ë‹ìŠ¨ì½”ë¦¬ì•„ / ì–´ì œ ë°©ì˜ë¶„)\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        def make_section(title, data):
            txt = f"ğŸ“¡ {title}\n"
            if data:
                for i, item in enumerate(data[:5]): # 5ìœ„ê¹Œì§€
                    txt += f" {i+1}ìœ„ {item['display_title']} | ({item['channel']}) | {item['rating']}\n"
            else:
                txt += "(ê²°ë°© ë˜ëŠ” ë°ì´í„° ì—†ìŒ)\n"
            return txt + "\n"
            
        report += make_section("ì§€ìƒíŒŒ (Top 5)", final_t)
        report += make_section("ì¢…í¸ (Top 5)", final_j)
        report += make_section("ì¼€ì´ë¸” (Top 5)", final_c)
        
        report += "ğŸ”— ì •ë³´: ë‹ìŠ¨ì½”ë¦¬ì•„"
        
        send_telegram(report)
        print("--- ì „ì†¡ ì™„ë£Œ ---")
        
    except Exception as e:
        err = traceback.format_exc()
        print(f"ğŸ”¥ ì¹˜ëª…ì  ì˜¤ë¥˜:\n{err}")
        send_telegram(f"ğŸš¨ ë´‡ ì˜¤ë¥˜ ë°œìƒ:\n{str(e)}")

if __name__ == "__main__":
    main()
