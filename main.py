import requests
from bs4 import BeautifulSoup
import datetime
import os
import re
import traceback # ì—ëŸ¬ ì¶”ì ìš©

# 1. í…”ë ˆê·¸ë¨ ì „ì†¡ í•¨ìˆ˜
def send_telegram(text):
    token = os.environ.get("TELEGRAM_TOKEN")
    chat_id = os.environ.get("CHAT_ID")
    if token and chat_id and len(text) > 0:
        try:
            url = f"https://api.telegram.org/bot{token}/sendMessage"
            requests.post(url, json={"chat_id": chat_id, "text": text, "disable_web_page_preview": True})
        except Exception as e:
            print(f"ì „ì†¡ ì‹¤íŒ¨: {e}")

# ==========================================
# [ì‚¬ìš©ì ì„¤ì • êµ¬ì—­]
# 1. ë´‡ì´ ìê¾¸ ë“œë¼ë§ˆë¥¼ ì§€ì›Œë²„ë¦¬ë©´ ì—¬ê¸°ì— ì œëª©ì„ ì¶”ê°€í•˜ì„¸ìš”. (ë¬´ì¡°ê±´ í¬í•¨ë¨)
# ë„ì–´ì“°ê¸° ì—†ì´ ì ì–´ë„ ë©ë‹ˆë‹¤.
FORCE_INCLUDE = [
    "ê²°í˜¼í•˜ìë§¹ê½ì•„", "ì¹œì ˆí•œì„ ì£¼ì”¨", "ìŠ¤ìº”ë“¤", "ì‹¬ì¥ì„í›”ì¹œê²Œì„", 
    "ìš©ê°ë¬´ìŒìš©ìˆ˜ì •", "ì„¸ë²ˆì§¸ê²°í˜¼", "ìš°ì•„í•œì œêµ­", "ë‚˜ì˜í•´ë¦¬ì—ê²Œ", 
    "ì¡°ë¦½ì‹ê°€ì¡±", "ì´í˜¼ìˆ™ë ¤ìº í”„"
]

# 2. ë“œë¼ë§ˆê°€ ì•„ë‹Œë° ìê¾¸ ë‚˜ì˜¤ë©´ ë‹¨ì–´ë¥¼ ì¶”ê°€í•˜ì„¸ìš”. (ë¬´ì¡°ê±´ ì œì™¸ë¨)
EXCLUDE_KEYWORDS = [
    "ë‰´ìŠ¤", "News", "ìŠ¤í¬ì¸ ", "ì•¼êµ¬", "ë² ì´ìŠ¤ë³¼", "íˆ¬ë°ì´", "ëª¨ë‹", "ì¸ê°„ê·¹ì¥", "ì•„ì¹¨ë§ˆë‹¹", 
    "ìƒí™œì˜ë‹¬ì¸", "ê°€ìš”ë¬´ëŒ€", "ë…¸ë˜ìë‘", "ë™ë¬¼ë†ì¥", "ì„œí”„ë¼ì´ì¦ˆ", "ë¯¸ìš´ìš°ë¦¬ìƒˆë¼", 
    "ë‚˜í˜¼ìì‚°ë‹¤", "ëŸ°ë‹ë§¨", "1ë°•2ì¼", "ë³µë©´ê°€ì™•", "ë¶ˆí›„ì˜ëª…ê³¡", "ìŠˆí¼ë§¨", "ê³¨ë•Œë¦¬ëŠ”", 
    "ë¼ë””ì˜¤ìŠ¤íƒ€", "ì•„ëŠ”í˜•ë‹˜", "ë™ì¹˜ë¯¸", "ì°ì „", "íƒì‚¬", "PDìˆ˜ì²©", "ê·¸ê²ƒì´", 
    "íŠ¹íŒŒì›", "ì‹œì‚¬", "í† ë¡ ", "ë‹¤í", "ì´ìŠˆ", "ì‚¬ê±´", "ë°˜ì¥", "íŠ¹ì„ ", "ì˜í™”", 
    "ì»¬íˆ¬ì‡¼", "ê°œê·¸", "ì½”ë¯¸ë””", "íŠ¸ë¡¯", "í˜„ì—­ê°€ì™•", "ë¶ˆíƒ€ëŠ”", "ë­‰ì³ì•¼", "í•œë¸”ë¦¬",
    "ìœ í€´ì¦ˆ", "ë™ìƒì´ëª½", "ì‚´ë¦¼ë‚¨", "ì‚¬ì¥ë‹˜", "ìµœê°•ì•¼êµ¬", "ì‹ ë‘ìˆ˜ì—…", "ê¸ˆìª½",
    "6ì‹œë‚´ê³ í–¥", "ê³ í–¥", "ìƒìƒ", "ì •ë³´", "í‹ˆë§Œë‚˜ë©´", "ì „ì§€ì ", "êµ¬í•´ì¤˜", "í™ˆì¦ˆ",
    "ìŠ¤í˜ì…œ", "ì¬ë°©ì†¡", "ë² ìŠ¤íŠ¸", "í•˜ì´ë¼ì´íŠ¸", "TVë™ë¬¼ë†ì¥"
]
# ==========================================

def clean_and_check_title(raw_title):
    # 1ë‹¨ê³„: ê´„í˜¸ ì¶”ì¶œ ë¡œì§ (ë‹ìŠ¨ ë°ì´í„° ì •ì œ)
    # "ì¼ì¼ë“œë¼ë§ˆ(ê²°í˜¼í•˜ìë§¹ê½ì•„)" -> "ê²°í˜¼í•˜ìë§¹ê½ì•„"
    match = re.search(r'\((.*?)\)', raw_title)
    
    final_title = raw_title
    if match:
        content = match.group(1).strip()
        if len(content) > 1:
            final_title = content
    else:
        final_title = raw_title.strip()
    
    # ê³µë°± ì œê±°í•œ íƒ€ì´í‹€ (ë¹„êµìš©)
    clean_title_nospace = final_title.replace(" ", "")

    # [ì•ˆì „ì¥ì¹˜ 1] ê°•ì œ í¬í•¨ ë¦¬ìŠ¤íŠ¸ í™•ì¸ (Whitelist)
    # ì—¬ê¸°ì— ìˆìœ¼ë©´ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ê²€ì‚¬ ì—†ì´ ë°”ë¡œ í†µê³¼!
    for force in FORCE_INCLUDE:
        if force.replace(" ", "") in clean_title_nospace:
            print(f"   âœ¨ ê°•ì œ í¬í•¨ë¨: {final_title}")
            return final_title

    # [ì•ˆì „ì¥ì¹˜ 2] ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
    for kw in EXCLUDE_KEYWORDS:
        if kw in clean_title_nospace or kw in raw_title.replace(" ", ""):
            print(f"   ğŸ—‘ï¸ ì œì™¸ë¨: {final_title} (í‚¤ì›Œë“œ: {kw})")
            return None # ì œì™¸

    return final_title

# 3. ë‹ìŠ¨ì½”ë¦¬ì•„ íŒŒì‹±
def fetch_nielsen_ratings(url, type_name):
    print(f"[{type_name}] ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {url}")
    # [ì¤‘ìš”] í—¤ë”ë¥¼ ë³´ê°•í•˜ì—¬ ì°¨ë‹¨ì„ ë°©ì§€í•¨
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.nielsenkorea.co.kr/',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
    }
    
    try:
        # íƒ€ì„ì•„ì›ƒì„ 30ì´ˆë¡œ ëŠ˜ë¦¼ (ì„œë²„ê°€ ëŠë¦´ ë•Œ ëŒ€ë¹„)
        res = requests.get(url, headers=headers, timeout=30)
        res.encoding = 'euc-kr' # ì¸ì½”ë”© ê³ ì •
        
        soup = BeautifulSoup(res.text, 'html.parser')
        results = []
        
        table = soup.find("table", class_="ranking_tb")
        if not table:
            print(f"âš ï¸ [{type_name}] í…Œì´ë¸” ì—†ìŒ (IP ì°¨ë‹¨ ê°€ëŠ¥ì„±)")
            return []
            
        rows = table.find_all("tr")
        print(f"   â„¹ï¸ {len(rows)}ê°œ í–‰ ë°œê²¬")
        
        for row in rows:
            cols = row.find_all("td")
            if len(cols) < 4: continue 
            
            try:
                channel = cols[1].get_text(strip=True)
                raw_title = cols[2].get_text(strip=True)
                rating = cols[3].get_text(strip=True)
                
                # ì œëª© ê²€ì¦
                clean_title = clean_and_check_title(raw_title)
                
                if clean_title:
                    try:
                        rating_val = float(rating.replace("%", "").strip())
                    except:
                        rating_val = 0.0
                        
                    results.append({
                        "channel": channel,
                        "title": clean_title,
                        "rating": rating,
                        "rating_val": rating_val
                    })
            except Exception as e:
                print(f"   âš ï¸ íŒŒì‹± ì—ëŸ¬: {e}")
                continue
            
        return results
        
    except Exception as e:
        print(f"[{type_name}] ì ‘ì† ì—ëŸ¬: {e}")
        raise e # ë©”ì¸ìœ¼ë¡œ ì—ëŸ¬ë¥¼ ë˜ì§

# 4. ë©”ì¸ ì‹¤í–‰ (ì•ˆì „ì¥ì¹˜ í¬í•¨)
def main():
    try:
        kst_now = datetime.datetime.utcnow() + datetime.timedelta(hours=9)
        yesterday = kst_now - datetime.timedelta(days=1)
        days = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
        date_str = yesterday.strftime(f"%Y-%m-%d({days[yesterday.weekday()]})")
        
        print(f"--- ì‹¤í–‰ ì‹œì‘ ({date_str} ê¸°ì¤€) ---")
        
        # 1. ì§€ìƒíŒŒ
        url_t = "https://www.nielsenkorea.co.kr/tv_terrestrial_day.asp?menu=Tit_1&sub_menu=1_1&area=00"
        data_t = fetch_nielsen_ratings(url_t, "ì§€ìƒíŒŒ")
        
        # 2. ì¢…í¸/ì¼€ì´ë¸”
        url_c = "https://www.nielsenkorea.co.kr/tv_cable_day.asp?menu=Tit_2&sub_menu=2_1&area=00"
        data_c = fetch_nielsen_ratings(url_c, "ì¢…í¸/ì¼€ì´ë¸”")
        
        # 3. ë°ì´í„° ì •ë ¬ ë° ë¶„ë¦¬
        data_t.sort(key=lambda x: x['rating_val'], reverse=True)
        
        jongpyeon_chs = ["JTBC", "MBN", "TV CHOSUN", "TVì¡°ì„ ", "ì±„ë„A"]
        list_j = []
        list_c = []
        
        for item in data_c:
            ch_upper = item['channel'].upper().replace(" ", "")
            if any(j in ch_upper for j in jongpyeon_chs):
                list_j.append(item)
            else:
                list_c.append(item)
        
        list_j.sort(key=lambda x: x['rating_val'], reverse=True)
        list_c.sort(key=lambda x: x['rating_val'], reverse=True)
                
        # 4. ë¦¬í¬íŠ¸ ì‘ì„±
        report = f"ğŸ“º {date_str} ë“œë¼ë§ˆ ì‹œì²­ë¥  ë­í‚¹\n(ë‹ìŠ¨ì½”ë¦¬ì•„ / ì–´ì œ ë°©ì˜ë¶„)\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        def add_section(title, data_list):
            txt = f"ğŸ“¡ {title}\n"
            if data_list:
                for i, item in enumerate(data_list[:5]):
                    txt += f" {i+1}ìœ„ {item['title']} | ({item['channel']}) | {item['rating']}\n"
            else:
                txt += "(ê²°ë°© ë˜ëŠ” ë°ì´í„° ì—†ìŒ)\n"
            return txt + "\n"

        report += add_section("ì§€ìƒíŒŒ", data_t)
        report += add_section("ì¢…í¸", list_j)
        report += add_section("ì¼€ì´ë¸”", list_c)
        
        report += "ğŸ”— ì •ë³´: ë‹ìŠ¨ì½”ë¦¬ì•„"
        
        send_telegram(report)
        print("--- ì „ì†¡ ì™„ë£Œ ---")
        
    except Exception as e:
        # [í•µì‹¬] í”„ë¡œê·¸ë¨ì´ ì£½ê¸° ì „ì— ì—ëŸ¬ ë‚´ìš©ì„ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë³´ëƒ„
        err_msg = traceback.format_exc()
        print(f"ğŸ”¥ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ:\n{err_msg}")
        send_telegram(f"ğŸš¨ ë´‡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ!\n\n{str(e)}")

if __name__ == "__main__":
    main()
