import requests
from bs4 import BeautifulSoup
import datetime
import os
import re

# 1. í…”ë ˆê·¸ë¨ ì „ì†¡
def send_telegram(text):
    token = os.environ.get("TELEGRAM_TOKEN")
    chat_id = os.environ.get("CHAT_ID")
    if token and chat_id and len(text) > 0:
        try:
            url = f"https://api.telegram.org/bot{token}/sendMessage"
            requests.post(url, json={"chat_id": chat_id, "text": text, "disable_web_page_preview": True})
        except Exception as e:
            print(f"ì „ì†¡ ì‹¤íŒ¨: {e}")

# 2. [í•µì‹¬] í˜„ì¬ ë°©ì˜ì¤‘ì¸ ë“œë¼ë§ˆ ì œëª© ë¦¬ìŠ¤íŠ¸ í™•ë³´ (Whitelist)
def get_current_drama_titles():
    print("ğŸ“‹ í˜„ì¬ ë°©ì˜ì¤‘ì¸ ë“œë¼ë§ˆ ë¦¬ìŠ¤íŠ¸ í™•ë³´ ì¤‘ (Daum ê²€ìƒ‰)...")
    
    # ì§€ìƒíŒŒ, ì¢…í¸, ì¼€ì´ë¸” ë“œë¼ë§ˆ ê²€ìƒ‰ ì¿¼ë¦¬
    queries = ["ì§€ìƒíŒŒ ë“œë¼ë§ˆ ì‹œì²­ë¥ ", "ì¢…í¸ ë“œë¼ë§ˆ ì‹œì²­ë¥ ", "ì¼€ì´ë¸” ë“œë¼ë§ˆ ì‹œì²­ë¥ "]
    drama_titles = set()
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'
    }
    
    for q in queries:
        try:
            url = f"https://search.daum.net/search?w=tot&q={q}"
            res = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # Daum ê²€ìƒ‰ê²°ê³¼ì—ì„œ ì œëª© ì¶”ì¶œ
            # (í´ë˜ìŠ¤ëª…ì€ ë³€í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ëŸ¬ í›„ë³´êµ° íƒìƒ‰)
            titles = soup.select(".tit_item, .fn_tit, .link_tit")
            
            for t in titles:
                # ì œëª© ì •ì œ (íŠ¹ìˆ˜ë¬¸ì ì œê±°, ê³µë°± ì œê±°)
                raw_title = t.get_text(strip=True)
                clean_title = re.sub(r'\[.*?\]|\(.*?\)', '', raw_title).strip() # ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±°
                if len(clean_title) > 1: # í•œ ê¸€ì ì œëª©ì€ ì œì™¸ (ì˜¤ë¥˜ ë°©ì§€)
                    drama_titles.add(clean_title)
                    
        except Exception as e:
            print(f"âš ï¸ ë“œë¼ë§ˆ ëª©ë¡ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬ ({q}): {e}")
            
    print(f"âœ… í™•ë³´ëœ ë“œë¼ë§ˆ ì œëª© ({len(drama_titles)}ê°œ): {list(drama_titles)[:5]} ...")
    return drama_titles

# 3. ë‹ìŠ¨ì½”ë¦¬ì•„ íŒŒì‹± í•¨ìˆ˜
def fetch_nielsen_ratings(url, type_name):
    print(f"[{type_name}] ë‹ìŠ¨ì½”ë¦¬ì•„ ë°ì´í„° ìˆ˜ì§‘: {url}")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'
    }
    
    try:
        res = requests.get(url, headers=headers, timeout=15)
        res.encoding = 'euc-kr' # í•œê¸€ ê¹¨ì§ ë°©ì§€
        
        soup = BeautifulSoup(res.text, 'html.parser')
        results = []
        
        table = soup.find("table", class_="ranking_tb")
        if not table:
            return []
            
        rows = table.find_all("tr")
        
        for row in rows:
            cols = row.find_all("td")
            if len(cols) < 4: continue 
            
            try:
                # ë‹ìŠ¨ ë°ì´í„° ì¶”ì¶œ
                # rankëŠ” ì—¬ê¸°ì„œ ê°€ì ¸ì˜¤ì§€ë§Œ, ë‚˜ì¤‘ì— ë“œë¼ë§ˆë¼ë¦¬ ë‹¤ì‹œ ë§¤ê¸¸ ê²ƒì„
                channel = cols[1].get_text(strip=True)
                title = cols[2].get_text(strip=True)
                rating = cols[3].get_text(strip=True)
                
                # ë‹ìŠ¨ ì œëª© ì •ì œ (ê³µë°± ë“±)
                clean_nielsen_title = title.strip()
                
                results.append({
                    "channel": channel,
                    "title": clean_nielsen_title,
                    "rating": rating
                })
            except: continue
            
        return results
        
    except Exception as e:
        print(f"â›” [{type_name}] ì ‘ì† ì—ëŸ¬: {e}")
        return []

# 4. ë°ì´í„° ë§¤ì¹­ ë° ìˆœìœ„ ì¬ì‚°ì •
def filter_and_rank_dramas(nielsen_data, whitelist_titles):
    filtered = []
    
    for item in nielsen_data:
        nielsen_title = item['title']
        
        # ë§¤ì¹­ ë¡œì§: Whitelist ì œëª©ì´ ë‹ìŠ¨ ì œëª© ì•ˆì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
        # ì˜ˆ: Whitelist "ê²°í˜¼í•˜ì ë§¹ê½ì•„" in Nielsen "ì¼ì¼ë“œë¼ë§ˆ(ê²°í˜¼í•˜ìë§¹ê½ì•„)"
        is_match = False
        
        # 1. ì •í™•í•œ í¬í•¨ ì—¬ë¶€ í™•ì¸
        for drama in whitelist_titles:
            # ê³µë°± ì œê±°í•˜ê³  ë¹„êµ (ì •í™•ë„ í–¥ìƒ)
            if drama.replace(" ", "") in nielsen_title.replace(" ", ""):
                is_match = True
                # ì œëª©ì„ ê¹”ë”í•œ Whitelist ì œëª©ìœ¼ë¡œ êµì²´ (ì„ íƒì‚¬í•­)
                item['display_title'] = drama 
                break
        
        # 2. (ë³´ì™„) ì œëª©ì— 'ë“œë¼ë§ˆ', 'ì‹œë¦¬ì¦ˆ'ê°€ ëª…ì‹œì ìœ¼ë¡œ ìˆìœ¼ë©´ ì¶”ê°€ í—ˆìš©
        if not is_match:
            if any(x in nielsen_title for x in ["ë“œë¼ë§ˆ", "ë¯¸ë‹ˆì‹œë¦¬ì¦ˆ", "ì—°ì†ê·¹"]):
                is_match = True
                item['display_title'] = nielsen_title # ì›ë˜ ì œëª© ì‚¬ìš©

        if is_match:
            # ì‹œì²­ë¥  ìˆ«ìë¡œ ë³€í™˜ (ì •ë ¬ìš©)
            try:
                item['rating_float'] = float(item['rating'].replace("%", "").strip())
            except:
                item['rating_float'] = 0.0
            filtered.append(item)
            
    # ì‹œì²­ë¥  ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    filtered.sort(key=lambda x: x['rating_float'], reverse=True)
    
    return filtered

# 5. ë©”ì¸ ì‹¤í–‰
def main():
    # ì‹œê°„ ì„¤ì •
    kst_now = datetime.datetime.utcnow() + datetime.timedelta(hours=9)
    yesterday = kst_now - datetime.timedelta(days=1)
    days = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
    date_str = yesterday.strftime(f"%Y-%m-%d({days[yesterday.weekday()]})")
    
    print(f"--- ì‹¤í–‰ ì‹œì‘ ({date_str} ê¸°ì¤€) ---")
    
    # 1. Whitelist í™•ë³´ (í˜„ì¬ ë°©ì˜ ë“œë¼ë§ˆ)
    active_dramas = get_current_drama_titles()
    
    # 2. ë‹ìŠ¨ ë°ì´í„° ìˆ˜ì§‘ (Raw Data)
    url_t = "https://www.nielsenkorea.co.kr/tv_terrestrial_day.asp?menu=Tit_1&sub_menu=1_1&area=00"
    raw_t = fetch_nielsen_ratings(url_t, "ì§€ìƒíŒŒ")
    
    url_c = "https://www.nielsenkorea.co.kr/tv_cable_day.asp?menu=Tit_2&sub_menu=2_1&area=00"
    raw_c = fetch_nielsen_ratings(url_c, "ì¢…í¸/ì¼€ì´ë¸”")
    
    # 3. ë§¤ì¹­ ë° í•„í„°ë§
    final_t = filter_and_rank_dramas(raw_t, active_dramas)
    final_c_all = filter_and_rank_dramas(raw_c, active_dramas)
    
    # 4. ì¢…í¸/ì¼€ì´ë¸” ë¶„ë¦¬ (ì±„ë„ëª… ê¸°ì¤€)
    jongpyeon_chs = ["JTBC", "MBN", "TV CHOSUN", "TVì¡°ì„ ", "ì±„ë„A"]
    final_j = []
    final_c = []
    
    for item in final_c_all:
        ch_upper = item['channel'].upper().replace(" ", "")
        if any(j in ch_upper for j in jongpyeon_chs):
            final_j.append(item)
        else:
            final_c.append(item)
            
    # 5. ë¦¬í¬íŠ¸ ì‘ì„±
    report = f"ğŸ“º {date_str} ë“œë¼ë§ˆ ì‹œì²­ë¥  ë­í‚¹\n(ë‹ìŠ¨ì½”ë¦¬ì•„ / ì–´ì œ ë°©ì˜ë¶„)\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    
    # ì§€ìƒíŒŒ
    report += "ğŸ“¡ ì§€ìƒíŒŒ\n"
    if final_t:
        for i, item in enumerate(final_t[:5]): # ìì²´ ìˆœìœ„ ë§¤ê¹€
            title = item.get('display_title', item['title'])
            report += f" {i+1}ìœ„ {title} | ({item['channel']}) | {item['rating']}%\n"
    else:
        report += "(ê²°ë°© ë˜ëŠ” ë°ì´í„° ì—†ìŒ)\n"
    report += "\n"

    # ì¢…í¸
    report += "ğŸ“¡ ì¢…í¸\n"
    if final_j:
        for i, item in enumerate(final_j[:5]):
            title = item.get('display_title', item['title'])
            report += f" {i+1}ìœ„ {title} | ({item['channel']}) | {item['rating']}%\n"
    else:
        report += "(ê²°ë°© ë˜ëŠ” ë°ì´í„° ì—†ìŒ)\n"
    report += "\n"
    
    # ì¼€ì´ë¸”
    report += "ğŸ“¡ ì¼€ì´ë¸”\n"
    if final_c:
        for i, item in enumerate(final_c[:5]):
            title = item.get('display_title', item['title'])
            report += f" {i+1}ìœ„ {title} | ({item['channel']}) | {item['rating']}%\n"
    else:
        report += "(ê²°ë°© ë˜ëŠ” ë°ì´í„° ì—†ìŒ)\n"
    report += "\n"
    
    report += "ğŸ”— ì •ë³´: ë‹ìŠ¨ì½”ë¦¬ì•„"
    
    send_telegram(report)
    print("--- ì „ì†¡ ì™„ë£Œ ---")

if __name__ == "__main__":
    main()
